{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff0ffb99",
   "metadata": {
    "papermill": {
     "duration": 0.00392,
     "end_time": "2024-12-19T19:03:33.603763",
     "exception": false,
     "start_time": "2024-12-19T19:03:33.599843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567a5b4c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-19T19:03:33.611654Z",
     "iopub.status.busy": "2024-12-19T19:03:33.611227Z",
     "iopub.status.idle": "2024-12-19T19:03:42.225400Z",
     "shell.execute_reply": "2024-12-19T19:03:42.224207Z"
    },
    "papermill": {
     "duration": 8.620866,
     "end_time": "2024-12-19T19:03:42.227853",
     "exception": false,
     "start_time": "2024-12-19T19:03:33.606987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.base import clone, BaseEstimator, RegressorMixin\n",
    "from copy import deepcopy\n",
    "import optuna\n",
    "from scipy.optimize import minimize\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from colorama import Fore, Style\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor, StackingRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SEED = 42\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14104d33",
   "metadata": {
    "papermill": {
     "duration": 0.003026,
     "end_time": "2024-12-19T19:03:42.234269",
     "exception": false,
     "start_time": "2024-12-19T19:03:42.231243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Process file and time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7b507e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T19:03:42.242050Z",
     "iopub.status.busy": "2024-12-19T19:03:42.241456Z",
     "iopub.status.idle": "2024-12-19T19:03:42.249893Z",
     "shell.execute_reply": "2024-12-19T19:03:42.248803Z"
    },
    "papermill": {
     "duration": 0.014994,
     "end_time": "2024-12-19T19:03:42.252256",
     "exception": false,
     "start_time": "2024-12-19T19:03:42.237262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 13.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "    \n",
    "    df = pd.DataFrame(stats, columns=[f\"Stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2431dbb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T19:03:42.261497Z",
     "iopub.status.busy": "2024-12-19T19:03:42.260743Z",
     "iopub.status.idle": "2024-12-19T19:03:42.271866Z",
     "shell.execute_reply": "2024-12-19T19:03:42.270791Z"
    },
    "papermill": {
     "duration": 0.01784,
     "end_time": "2024-12-19T19:03:42.273965",
     "exception": false,
     "start_time": "2024-12-19T19:03:42.256125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim*3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim*3, encoding_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim*2, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, input_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim*2, input_dim*3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim*3, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "def perform_autoencoder(df, encoding_dim=50, epochs=50, batch_size=32):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    \n",
    "    data_tensor = torch.FloatTensor(df_scaled)\n",
    "    \n",
    "    input_dim = data_tensor.shape[1]\n",
    "    autoencoder = AutoEncoder(input_dim, encoding_dim)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(autoencoder.parameters())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(data_tensor), batch_size):\n",
    "            batch = data_tensor[i : i + batch_size]\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed = autoencoder(batch)\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}]')\n",
    "                 \n",
    "    with torch.no_grad():\n",
    "        encoded_data = autoencoder.encoder(data_tensor).numpy()\n",
    "        \n",
    "    df_encoded = pd.DataFrame(encoded_data, columns=[f'Enc_{i + 1}' for i in range(encoded_data.shape[1])])\n",
    "    \n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8703629a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T19:03:42.282283Z",
     "iopub.status.busy": "2024-12-19T19:03:42.281923Z",
     "iopub.status.idle": "2024-12-19T19:05:04.869222Z",
     "shell.execute_reply": "2024-12-19T19:05:04.868115Z"
    },
    "papermill": {
     "duration": 82.593929,
     "end_time": "2024-12-19T19:05:04.871427",
     "exception": false,
     "start_time": "2024-12-19T19:03:42.277498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:22<00:00, 12.12it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  9.16it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c7f939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T19:05:04.915299Z",
     "iopub.status.busy": "2024-12-19T19:05:04.914457Z",
     "iopub.status.idle": "2024-12-19T19:05:26.842704Z",
     "shell.execute_reply": "2024-12-19T19:05:26.841191Z"
    },
    "papermill": {
     "duration": 21.954071,
     "end_time": "2024-12-19T19:05:26.846510",
     "exception": false,
     "start_time": "2024-12-19T19:05:04.892439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.6832]\n",
      "Epoch [20/100], Loss: 1.6832]\n",
      "Epoch [30/100], Loss: 1.6832]\n",
      "Epoch [40/100], Loss: 1.6393]\n",
      "Epoch [50/100], Loss: 1.5593]\n",
      "Epoch [60/100], Loss: 1.5489]\n",
      "Epoch [70/100], Loss: 1.5290]\n",
      "Epoch [80/100], Loss: 1.5126]\n",
      "Epoch [90/100], Loss: 1.5074]\n",
      "Epoch [100/100], Loss: 1.5144]\n",
      "Epoch [10/100], Loss: 1.0025]\n",
      "Epoch [20/100], Loss: 0.6837]\n",
      "Epoch [30/100], Loss: 0.4276]\n",
      "Epoch [40/100], Loss: 0.4271]\n",
      "Epoch [50/100], Loss: 0.4271]\n",
      "Epoch [60/100], Loss: 0.4271]\n",
      "Epoch [70/100], Loss: 0.4271]\n",
      "Epoch [80/100], Loss: 0.4271]\n",
      "Epoch [90/100], Loss: 0.4271]\n",
      "Epoch [100/100], Loss: 0.4271]\n"
     ]
    }
   ],
   "source": [
    "df_train = train_ts.drop('id', axis=1)\n",
    "df_test = test_ts.drop('id', axis=1)\n",
    "\n",
    "train_ts_encoded = perform_autoencoder(df_train, encoding_dim=60, epochs=100, batch_size=32)\n",
    "test_ts_encoded = perform_autoencoder(df_test, encoding_dim=60, epochs=100, batch_size=32)\n",
    "\n",
    "time_series_cols = train_ts_encoded.columns.tolist()\n",
    "train_ts_encoded[\"id\"]=train_ts[\"id\"]\n",
    "test_ts_encoded['id']=test_ts[\"id\"]\n",
    "\n",
    "train = pd.merge(train, train_ts_encoded, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts_encoded, how=\"left\", on='id')\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "numeric_cols = train.select_dtypes(include=['float64', 'int64']).columns\n",
    "imputed_data = imputer.fit_transform(train[numeric_cols])\n",
    "train_imputed = pd.DataFrame(imputed_data, columns=numeric_cols)\n",
    "train_imputed['sii'] = train_imputed['sii'].round().astype(int)\n",
    "for col in train.columns:\n",
    "    if col not in numeric_cols:\n",
    "        train_imputed[col] = train[col]\n",
    "        \n",
    "train = train_imputed\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test  = test .drop('id', axis=1)   \n",
    "\n",
    "featuresCols = ['Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-CGAS_Score', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total', \n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', \n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "train = train[featuresCols]\n",
    "train = train.dropna(subset='sii')\n",
    "\n",
    "featuresCols = ['Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-CGAS_Score', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total', \n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', \n",
    "                'PreInt_EduHx-computerinternet_hoursday']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "test = test[featuresCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67814736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T19:05:26.906977Z",
     "iopub.status.busy": "2024-12-19T19:05:26.905948Z",
     "iopub.status.idle": "2024-12-19T19:05:26.921184Z",
     "shell.execute_reply": "2024-12-19T19:05:26.920002Z"
    },
    "papermill": {
     "duration": 0.047773,
     "end_time": "2024-12-19T19:05:26.923372",
     "exception": false,
     "start_time": "2024-12-19T19:05:26.875599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    \n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train['sii']\n",
    "\n",
    "    SKF = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=1, random_state=SEED)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead') # Nelder-Mead | # Powell\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': tpTuned\n",
    "    })\n",
    "\n",
    "    return submission,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb7b9dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T19:05:26.966494Z",
     "iopub.status.busy": "2024-12-19T19:05:26.965800Z",
     "iopub.status.idle": "2024-12-19T19:05:26.972092Z",
     "shell.execute_reply": "2024-12-19T19:05:26.970970Z"
    },
    "papermill": {
     "duration": 0.030172,
     "end_time": "2024-12-19T19:05:26.974090",
     "exception": false,
     "start_time": "2024-12-19T19:05:26.943918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params3 = {'lambda_l1': 2.9209409268664883,\n",
    " 'lambda_l2': 0.00012976118112242174,\n",
    " 'num_leaves': 202,\n",
    " 'feature_fraction': 0.8038056112369449,\n",
    " 'bagging_fraction': 0.6991108077097957,\n",
    " 'bagging_freq': 3,\n",
    " \"learning_rate\": 0.05,\n",
    " 'min_child_samples': 85}\n",
    "catboost_params = {'learning_rate': 0.019252771685694288,\n",
    " 'depth': 7,\n",
    " 'subsample': 0.40628186539007644,\n",
    " 'colsample_bylevel': 0.6904206855559013,\n",
    " 'min_data_in_leaf': 38}\n",
    "XGB_Params = {'lambda_l1': 0.1543921843752799,\n",
    " 'lambda_l2': 0.000281461450194636,\n",
    " 'num_leaves': 2,\n",
    " 'feature_fraction': 0.6799895242815174,\n",
    " 'bagging_fraction': 0.5050148144157642,\n",
    " 'bagging_freq': 1,\n",
    " 'min_child_samples': 86}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35e502f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T19:05:27.019377Z",
     "iopub.status.busy": "2024-12-19T19:05:27.018984Z",
     "iopub.status.idle": "2024-12-19T19:05:27.023928Z",
     "shell.execute_reply": "2024-12-19T19:05:27.022886Z"
    },
    "papermill": {
     "duration": 0.029896,
     "end_time": "2024-12-19T19:05:27.025848",
     "exception": false,
     "start_time": "2024-12-19T19:05:26.995952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Light = lgb.LGBMRegressor(**params3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9006e6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T19:05:27.069598Z",
     "iopub.status.busy": "2024-12-19T19:05:27.068729Z",
     "iopub.status.idle": "2024-12-19T19:05:28.921404Z",
     "shell.execute_reply": "2024-12-19T19:05:28.920292Z"
    },
    "papermill": {
     "duration": 1.877401,
     "end_time": "2024-12-19T19:05:28.924297",
     "exception": false,
     "start_time": "2024-12-19T19:05:27.046896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:01<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.6153\n",
      "Mean Validation QWK ---> 0.4742\n",
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.522\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Submission,model = TrainML(Light,test)\n",
    "#Mean Train QWK --> 0.6147\n",
    "#Mean Validation QWK ---> 0.4666\n",
    "#----> || Optimized QWK SCORE ::  0.523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f217e66c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T19:05:28.968112Z",
     "iopub.status.busy": "2024-12-19T19:05:28.967720Z",
     "iopub.status.idle": "2024-12-19T19:05:28.982504Z",
     "shell.execute_reply": "2024-12-19T19:05:28.981289Z"
    },
    "papermill": {
     "duration": 0.039416,
     "end_time": "2024-12-19T19:05:28.984660",
     "exception": false,
     "start_time": "2024-12-19T19:05:28.945244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sii\n",
      "0    14\n",
      "1     6\n",
      "Name: count, dtype: int64\n",
      "CPU times: user 5.15 ms, sys: 101 µs, total: 5.26 ms\n",
      "Wall time: 9.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Submission.to_csv('submission.csv', index=False)\n",
    "print(Submission['sii'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    },
    {
     "datasetId": 921302,
     "sourceId": 7453542,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 121.029813,
   "end_time": "2024-12-19T19:05:31.412303",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-19T19:03:30.382490",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
